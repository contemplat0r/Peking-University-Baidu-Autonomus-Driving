{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage import color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d\n",
    "from torch.optim import Adam\n",
    "from torch.utils import data\n",
    "\n",
    "import natural_images_dataset_loader\n",
    "from natural_images_dataset_loader import get_dataset_info, get_files_label_map, make_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(natural_images_dataset_loader)\n",
    "from natural_images_dataset_loader import get_class_label_map, NaturalImagesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalImagesNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, classes_num):\n",
    "        super(NaturalImagesNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv0 = Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=0)\n",
    "        self.fc_out = Linear(62 * 62 * in_channels, classes_num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"forward: x.shape before conv0(x)\", x.shape)\n",
    "        x = self.conv0(x)\n",
    "        #print(\"forward: x.shape after conv0(x)\", x.shape)\n",
    "        x = x.view(-1, 62 * 62 * self.in_channels)\n",
    "        x = self.fc_out(x)\n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        x = F.log_softmax(x)\n",
    "        #print(\"forward, x after log_softmax:\\n\", x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 4, 'shuffle': True}\n",
    "class_label_map = get_class_label_map('../input/natural-images/natural_images/*')\n",
    "\n",
    "ni_ds_train = NaturalImagesDataset(class_label_map, resize_sizes=(64, 64))\n",
    "ni_train_dataloader = data.DataLoader(ni_ds_train, **params)\n",
    "\n",
    "ni_ds_valid = NaturalImagesDataset(class_label_map, valid=True, resize_sizes=(64, 64))\n",
    "ni_valid_loader = data.DataLoader(ni_ds_valid, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = get_dataset_info('../input/natural-images/natural_images/*')\n",
    "print(\"len(dataset_info):\", len(dataset_info))\n",
    "print(\"type(dataset_info[0][2]): \", type(dataset_info[0][2]))\n",
    "print(\"dataset_info[0][2][:10]: \", dataset_info[0][2][:10])\n",
    "files_label_map = get_files_label_map(dataset_info)\n",
    "print(get_files_label_map(dataset_info)[2000:2020])\n",
    "#print(type(make_loaders(files_label_map)))\n",
    "train_dl, valid_dl, test_dl = make_loaders(files_label_map, train_test_split_ratio=0.25, train_valid_split_ratio=0.25)\n",
    "print(type(train_dl), type(valid_dl), type(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_num = len(dataset_info)\n",
    "print(classes_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img, label = next(iter(ni_train_dataloader))\n",
    "img, label = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(img)\n",
    "#img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaturalImagesNet(input_channels, classes_num)\n",
    "#model = NaturalImagesNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epoch = 12\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_of_epoch):\n",
    "    # loop over the dataset multiple times\n",
    "    \n",
    "    avg_train_cost = 0\n",
    "    avg_val_cost = 0\n",
    "    \n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(ni_train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(\"epoch: {}, batch: {} train running loss: {}\".format(epoch, i, train_running_loss / 20))\n",
    "            train_running_loss = 0.0\n",
    "            \n",
    "        avg_train_cost = avg_train_cost + loss.data\n",
    "                \n",
    "    if epoch % 2 != 0:\n",
    "        print(\"epoch {}, avg train cost: {}\".format(epoch, avg_train_cost))\n",
    "        avg_train_cost = 0\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(ni_valid_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "                \n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_losses.append(val_loss)\n",
    "                \n",
    "            val_running_loss += val_loss.item()\n",
    "                \n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print(\"epoch: {}, batch: {} val running loss: {}\".format(epoch, i, val_running_loss / 20))\n",
    "                val_running_loss = 0.0\n",
    "                \n",
    "        avg_val_cost = avg_val_cost + loss.data\n",
    "                \n",
    "        if epoch % 2 != 0:\n",
    "            print(\"epoch {}, avg val cost: {}\".format(epoch, avg_val_cost))\n",
    "            avg_val_cost = 0\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "time_elapsed = time.time() - start_time\n",
    "print(\n",
    "    'Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")#x = self.relu(x)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = Variable(train_x), Variable(train_y, requires_grad=False)\n",
    "\n",
    "#pred = model(x)\n",
    "\n",
    "#final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "#accuracy_score(train_y, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './my_first_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(ni_valid_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print('GroundTruth: ', ' '.join('%5s' % class_label_map[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model0 = NaturalImagesNet()\n",
    "#model0.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs = model0(images)\n",
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#print('Predicted: ', ' '.join('%5s' % class_label_map[predicted[j]]\n",
    "#                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in ni_valid_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.to(device, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in ni_valid_loader:\n",
    "        images, labels = data\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images.to(device, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        #for i in range(4):\n",
    "        for i in range(2):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        class_label_map[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
